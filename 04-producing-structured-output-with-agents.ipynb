{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a64fd8",
   "metadata": {},
   "source": [
    "### Microsoft Agent Framework-Part4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55b13c2",
   "metadata": {},
   "source": [
    "#### Create the agent with structured output\n",
    "- An agent with structured output is an AI agent that returns information in a fixed schema — not free text — using models like Pydantic to enforce predictable JSON output.\n",
    "\n",
    "- It ensures the model never improvises or adds fluff; instead, it produces clean, machine-readable fields (like name, age, skills, experience) that backend systems can trust.\n",
    "\n",
    "- Structured output is essential when integrating AI into real applications (ATS, HRMS, ERP, CRM) because the output follows a strict format that downstream automations rely on.\n",
    "\n",
    "- The ChatAgent is built on top of any chat client implementation that supports structured output. The ChatAgent uses the response_format parameter to specify the desired output schema.\n",
    "\n",
    "- When creating or running the agent, you can provide a Pydantic model that defines the structure of the expected output.\n",
    "\n",
    "- This example creates an agent that produces structured output in the form of a JSON object that conforms to a Pydantic model schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a95d2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class PersonInfo(BaseModel):\n",
    "    name: str | None = None\n",
    "    age: int | None = None\n",
    "    occupation: str | None = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aa82d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "agent = AzureOpenAIChatClient(credential=AzureCliCredential()).create_agent(\n",
    "    name=\"HelpfulAssistant\",\n",
    "    instructions=\"You are a helpful assistant that extracts person information from text.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce315e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='John Sir' age=35 occupation='software engineer'\n"
     ]
    }
   ],
   "source": [
    "response = await agent.run(\n",
    "    \"John Sir is a 35-year-old software engineer who loves automation.\",\n",
    "    response_format=PersonInfo\n",
    ")\n",
    "\n",
    "if response.value:\n",
    "    info = response.value\n",
    "    print(info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3babb4",
   "metadata": {},
   "source": [
    "### Use Case: Parsing a Resume PDF to Get Structured Output\n",
    "\n",
    "\n",
    "“Imagine you're building an AI-powered hiring system. Candidates upload resumes in PDF format, but HR doesn’t want free-form text — they want clean structured data:\n",
    "\n",
    "Name\n",
    "\n",
    "Email\n",
    "\n",
    "Phone\n",
    "\n",
    "Skills\n",
    "\n",
    "Years of experience\n",
    "\n",
    "Education\n",
    "\n",
    "Last job title\n",
    "\n",
    "Using MAF structured output + PDF parsing, we can convert ANY resume into clean JSON ready for our ATS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10929609",
   "metadata": {},
   "source": [
    "**Step-1: Extract Resume Text Using PyMuPDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3d6352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 2 \n",
      "Mountain View, CA 94041 \n",
      "650-336-4590 | johnsir@gmail.com\n",
      "linkedin.com/in/johnsir | \n",
      "johnsir.github.io \n",
      "John Sir \n",
      " Data Scientist \n",
      "Professional Profile \n",
      "Passionate about data analysis and experiments, mainly focused on user behavior, experience, and engagement, with a solid \n",
      "background in data science and statistics, and extensive experience using data insights to drive business growth. \n",
      "Education\n",
      "2016 \n",
      "University of California, Berkeley \n",
      "Master of Information and Data Science \n",
      "GPA: 3.93\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "resume_text = extract_text_from_pdf(\"./data/Resume-1.pdf\")\n",
    "print(resume_text[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5591b355",
   "metadata": {},
   "source": [
    "**Step-2: Define a Richer Pydantic Model for Resume Parsing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ea11ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "class ResumeInfo(BaseModel):\n",
    "    name: Optional[str] = None\n",
    "    email: Optional[str] = None\n",
    "    phone: Optional[str] = None\n",
    "    skills: List[str] = []\n",
    "    total_experience_years: Optional[float] = None\n",
    "    last_job_title: Optional[str] = None\n",
    "    education: Optional[str] = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1d3b8",
   "metadata": {},
   "source": [
    "**Step-3: Create Resume Extraction Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad444bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_agent = AzureOpenAIChatClient(credential=AzureCliCredential()).create_agent(\n",
    "    name=\"ResumeParser\",\n",
    "    instructions=\"\"\"\n",
    "    You are an advanced AI Resume Parser.\n",
    "    Extract structured candidate information ONLY in the schema provided.\n",
    "    Do NOT add extra text. Do NOT summarize.\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b785cd5",
   "metadata": {},
   "source": [
    "**Step-4: Run Structured Extraction on the Resume**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "613b1d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='John Sir' email='johnsir@gmail.com' phone='650-336-4590' skills=['R', 'Python', 'SQL', 'Hadoop', 'Hive', 'MrJob', 'Tableau', 'Git', 'AWS', 'SPSS', 'SAS', 'Matlab', 'Spark', 'Storm', 'Bash', 'EViews', 'Demetra+', 'D3.js', 'Gephi', 'Neo4j', 'QGIS'] total_experience_years=5.0 last_job_title='Data Scientist' education='Master of Information and Data Science from University of California, Berkeley'\n"
     ]
    }
   ],
   "source": [
    "extracted = await resume_agent.run(\n",
    "    resume_text,\n",
    "    response_format=ResumeInfo\n",
    ")\n",
    "\n",
    "if extracted.value:\n",
    "    parsed_resume = extracted.value\n",
    "    print(parsed_resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb158e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'agent_run_response',\n",
       " 'messages': [{'type': 'chat_message',\n",
       "   'role': {'type': 'role', 'value': 'assistant'},\n",
       "   'contents': [{'type': 'text',\n",
       "     'text': '{\"name\":\"John Sir\",\"email\":\"johnsir@gmail.com\",\"phone\":\"650-336-4590\",\"skills\":[\"R\",\"Python\",\"SQL\",\"Hadoop\",\"Hive\",\"MrJob\",\"Tableau\",\"Git\",\"AWS\",\"SPSS\",\"SAS\",\"Matlab\",\"Spark\",\"Storm\",\"Bash\",\"EViews\",\"Demetra+\",\"D3.js\",\"Gephi\",\"Neo4j\",\"QGIS\"],\"total_experience_years\":5,\"last_job_title\":\"Data Scientist\",\"education\":\"Master of Information and Data Science from University of California, Berkeley\"}'}],\n",
       "   'author_name': 'ResumeParser',\n",
       "   'additional_properties': {}}],\n",
       " 'response_id': 'chatcmpl-CfUXB8pwDUcHG0v5N1JTmSCsAQKJt',\n",
       " 'created_at': '2025-11-24T22:50:57.000000Z',\n",
       " 'usage_details': {'type': 'usage_details',\n",
       "  'input_token_count': 1637,\n",
       "  'output_token_count': 114,\n",
       "  'total_token_count': 1751},\n",
       " 'additional_properties': {'system_fingerprint': 'fp_efad92c60b',\n",
       "  'logprobs': None}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=extracted.to_dict()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fc8045c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\":\"John Sir\",\"email\":\"johnsir@gmail.com\",\"phone\":\"650-336-4590\",\"skills\":[\"R\",\"Python\",\"SQL\",\"Hadoop\",\"Hive\",\"MrJob\",\"Tableau\",\"Git\",\"AWS\",\"SPSS\",\"SAS\",\"Matlab\",\"Spark\",\"Storm\",\"Bash\",\"EViews\",\"Demetra+\",\"D3.js\",\"Gephi\",\"Neo4j\",\"QGIS\"],\"total_experience_years\":5,\"last_job_title\":\"Data Scientist\",\"education\":\"Master of Information and Data Science from University of California, Berkeley\"}'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = r['messages'][0]['contents'][0]['text']\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32d95cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John Sir',\n",
       " 'email': 'johnsir@gmail.com',\n",
       " 'phone': '650-336-4590',\n",
       " 'skills': ['R',\n",
       "  'Python',\n",
       "  'SQL',\n",
       "  'Hadoop',\n",
       "  'Hive',\n",
       "  'MrJob',\n",
       "  'Tableau',\n",
       "  'Git',\n",
       "  'AWS',\n",
       "  'SPSS',\n",
       "  'SAS',\n",
       "  'Matlab',\n",
       "  'Spark',\n",
       "  'Storm',\n",
       "  'Bash',\n",
       "  'EViews',\n",
       "  'Demetra+',\n",
       "  'D3.js',\n",
       "  'Gephi',\n",
       "  'Neo4j',\n",
       "  'QGIS'],\n",
       " 'total_experience_years': 5,\n",
       " 'last_job_title': 'Data Scientist',\n",
       " 'education': 'Master of Information and Data Science from University of California, Berkeley'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "data = json.loads(raw)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6c15fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R',\n",
       " 'Python',\n",
       " 'SQL',\n",
       " 'Hadoop',\n",
       " 'Hive',\n",
       " 'MrJob',\n",
       " 'Tableau',\n",
       " 'Git',\n",
       " 'AWS',\n",
       " 'SPSS',\n",
       " 'SAS',\n",
       " 'Matlab',\n",
       " 'Spark',\n",
       " 'Storm',\n",
       " 'Bash',\n",
       " 'EViews',\n",
       " 'Demetra+',\n",
       " 'D3.js',\n",
       " 'Gephi',\n",
       " 'Neo4j',\n",
       " 'QGIS']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['skills']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cac9aed",
   "metadata": {},
   "source": [
    "Benefits\n",
    "\n",
    "1. ATS Integration:\n",
    "\n",
    "    Clean JSON goes directly into your Applicant Tracking System.\n",
    "\n",
    "2. No Post-Processing Required:\n",
    "\n",
    "    No regex, no custom parsing — the LLM formats everything for you.\n",
    "\n",
    "3. Zero Hallucination Formatting:\n",
    "\n",
    "    Schema forces strict JSON output.\n",
    "\n",
    "4. Scalable for Enterprises:\n",
    "    \n",
    "    Thousands of resumes per day → automated.\n",
    "\n",
    "5. Reusable Across Domains\n",
    "\n",
    "Same technique works for:\n",
    "\n",
    "        Invoice parsing\n",
    "\n",
    "        Contract extraction\n",
    "\n",
    "        Support ticket classification\n",
    "\n",
    "        Insurance claims\n",
    "\n",
    "        Medical records"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
